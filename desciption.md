‚≠ê PROJECT NAME: SMART APPROVAL AI
AI-Based Document Analysis, Performance Indicators & Reporting System for UGC & AICTE Reviewers
________________________________________
‚≠ê 1. OVERVIEW ‚Äî WHAT THIS PROJECT IS
Smart Approval AI is a reviewer-facing AI tool (NOT an institution portal) that automatically analyzes institutional documents submitted for UGC/AICTE approvals and produces:
‚Ä¢	Performance scores on official KPI metrics
‚Ä¢	Document sufficiency percentage
‚Ä¢	Risk/compliance flags
‚Ä¢	Evidence-backed structured data
‚Ä¢	Past-performance trends
‚Ä¢	Official downloadable PDF report
This system is built to assist government reviewers, not institutions.
It performs all document understanding, extraction, scoring, and reporting automatically using:
‚Ä¢	Unstructured-IO (for parsing, OCR, segmentation)
‚Ä¢	GPT-5 Nano (classification + extraction + for every AI features + chatbot)
‚Ä¢	GPT-5 Mini (fallback)
‚Ä¢	FastAPI backend
‚Ä¢	Next.js reviewer dashboard
All functions are designed to solve the exact Expected Solution:
‚ÄúAI-based tracking system for institutional data and performance with report generation, performance indicators, and sufficiency of documents.‚Äù
________________________________________
‚≠ê 2. THE PROBLEM WE SOLVE
UGC & AICTE reviewers must manually evaluate:
‚Ä¢	Hundreds of pages of institutional documents
‚Ä¢	Approvals, certificates, faculty lists, infrastructure, labs, placements, research
‚Ä¢	Document completeness
‚Ä¢	Performance across years
‚Ä¢	Compliance & risk flags
‚Ä¢	Final scoring + reporting
This is slow, repetitive, inconsistent, and error-prone.
Our system automates this entire process.
________________________________________
‚≠ê 3. HOW THE SOLUTION WORKS (TOP-LEVEL)
Smart Approval AI performs:
1.	Document Upload
2.	Document Parsing (OCR + segmentation)
3.	AI Classification (doc_type detection)
4.	AI Structured Data Extraction
5.	Sufficiency Scoring
6.	KPI Performance Scoring
7.	Trend Analysis
8.	Compliance Scoring
9.	Evidence Collection
10.	Reviewer Dashboard
11.	PDF Report Generation
12.	Chatbot Assistant Explanation
This is exactly what the PS asked for ‚Äî not more, not less.
________________________________________
‚≠ê 4. DETAILED MODULE-BY-MODULE EXPLANATION
Now the full deep detail ‚Äî what each module does, why it exists, and how it uses AI.
________________________________________
üîµ MODULE 1 ‚Äî Dual Reviewer Mode (UGC / AICTE)
When the user opens the tool, they select:
‚Ä¢	UGC Reviewer
‚Ä¢	AICTE Reviewer
This selection affects everything:
‚Ä¢	Required documents list
‚Ä¢	KPI formulas
‚Ä¢	Compliance rules
‚Ä¢	Terminology
‚Ä¢	Report templates
‚Ä¢	Weightage of metrics
The entire system reroutes based on mode.
(Exactly required by the problem statement.)
________________________________________
üîµ MODULE 2 ‚Äî Document Upload & Intake
Reviewer uploads files:
‚Ä¢	PDF
‚Ä¢	DOCX
‚Ä¢	PPTX
‚Ä¢	XLSX
‚Ä¢	Scanned images
‚Ä¢	ZIP
Features:
‚Ä¢	Drag & Drop
‚Ä¢	File rename/delete
‚Ä¢	Auto file size check
‚Ä¢	Batch ID assignment
‚Ä¢	Resume previous batch
‚Ä¢	Show upload progress
Also supports:
üìå WhatsApp-triggered analysis
(Meaning: A reviewer can send files to the system via WhatsApp, and the same analysis pipeline runs.)
This is an alternate input channel, not a complex ingestion system.
________________________________________
üîµ MODULE 3 ‚Äî Unified Document Preprocessing Engine (Unstructured-IO)
Unstructured-IO automatically:
‚Ä¢	Extracts text
‚Ä¢	Performs OCR
‚Ä¢	Segments into:
o	paragraphs
o	tables
o	lists
o	headers
o	footers
o	titles
‚Ä¢	Splits by layout blocks
‚Ä¢	Converts PDF pages into PNG images for evidence
Why this matters:
Indian institutional documents are messy (scans, blurred images, tables embedded in PDFs).
Unstructured makes them analyzable for GPT.
________________________________________
üîµ MODULE 4 ‚Äî Routing Engine
Before any AI call, the system determines:
‚Ä¢	Should OCR be applied?
‚Ä¢	Is it a scanned image?
‚Ä¢	Is it encrypted?
‚Ä¢	What extraction strategy should be used?
‚Ä¢	Should the file be chunked?
‚Ä¢	Which doc types it might be?
It creates a processing_plan.json, ensuring the pipeline behaves predictably.
This prevents errors and makes the AI processing stable.
________________________________________
üîµ MODULE 5 ‚Äî AI Classification Engine (GPT-5 Nano/Mini)
Each document is passed to an LLM for classification:
The LLM returns:
{
  "doc_type": "faculty_list",
  "confidence": 0.92,
  "evidence": {
    "page": 1,
    "snippet": "List of faculty members..."
  }
}
Example doc_types include:
‚Ä¢	fire_noc
‚Ä¢	fee_structure
‚Ä¢	faculty_list
‚Ä¢	infrastructure_report
‚Ä¢	placement_report
‚Ä¢	research_publications
‚Ä¢	academic_calendar
‚Ä¢	lab_equipment_list
GPT-5 Nano is used because:
‚Ä¢	High accuracy
‚Ä¢	Fast
‚Ä¢	Cheap
‚Ä¢	Great at classification tasks in few-shot prompts
GPT-5 Mini is fallback when JSON fails or confidence < threshold.
________________________________________
üîµ MODULE 6 ‚Äî AI Extraction Engine (GPT-5 Nano)
This is the heart of the system.
For each document, LLM extracts the structured fields required for KPIs and sufficiency:
Examples:
‚Ä¢	Faculty count
‚Ä¢	Qualification breakdown
‚Ä¢	Built-up area
‚Ä¢	Lab count
‚Ä¢	Research publication numbers
‚Ä¢	Placement data
‚Ä¢	Program-level accreditation
‚Ä¢	Fire NOC expiration date
‚Ä¢	Fee details
‚Ä¢	Infra facilities
‚Ä¢	Hostel capacity
‚Ä¢	Safety certificates
LLM is prompted with strict JSON schema.
Includes:
‚Ä¢	Field evidence (page + snippet)
‚Ä¢	Confidence %
‚Ä¢	Chunk merging
‚Ä¢	Validation
‚Ä¢	Error correction re-prompting
This makes the output auditable, accurate, and government-ready.
________________________________________
üîµ MODULE 7 ‚Äî Document Quality Intelligence
The system evaluates documents for:
‚Ä¢	Duplicates (SHA checksum)
‚Ä¢	Outdated documents (expiry date parsing)
‚Ä¢	Low-quality scans (OCR certainty scores)
‚Ä¢	Invalid documents (contradicting classification)
These are used in the sufficiency penalty formula.
________________________________________
üîµ MODULE 8 ‚Äî Document Sufficiency Engine (EXACT PS REQUIREMENT)
UGC & AICTE require a specific set of mandatory documents.
We compute how complete the submission is:
base_pct = (P/R)*100
penalty = D*2 + O*4 + L*5 + I*7
penalty = min(penalty, 50)
sufficiency = max(0, base_pct - penalty)
Where:
‚Ä¢	P = Present
‚Ä¢	R = Required
‚Ä¢	D = Duplicate
‚Ä¢	O = Outdated
‚Ä¢	L = Low quality
‚Ä¢	I = Invalid
Displayed as:
‚Ä¢	Total %.
‚Ä¢	Color-coded badge (Red/Yellow/Green)
‚Ä¢	Missing documents list
‚Ä¢	Penalty breakdown
This is exactly what the problem statement explicitly wants.
________________________________________
üîµ MODULE 9 ‚Äî KPI Engine (UGC & AICTE)
Each KPI is normalized to 0‚Äì100.
Example for AICTE:
1.	FSR Score
2.	Infrastructure Score
3.	Placement Index
4.	Lab Compliance Index
Example for UGC:
1.	Research Index
2.	Governance Score
3.	Student Outcome Index
Each KPI uses extracted fields + fixed formulas.
Final overall scores:
‚Ä¢	AICTE Overall Score
‚Ä¢	UGC Overall Score
This is the "performance indicator" part of the PS.
________________________________________
üîµ MODULE 10 ‚Äî Trend Analysis (3‚Äì5 years)
Simplified:
‚Ä¢	Show performance trends only if past years exist , if doesn‚Äôt exist then should say it doesn‚Äôt exist.
‚Ä¢	Plot KPIs across years
‚Ä¢	No interpolation for missing years
‚Ä¢	Clean line chart
Realistic and easy to compute.
________________________________________
üîµ MODULE 11 ‚Äî Compliance & Risk Engine
Loads rule sets from JSON rule base:
‚Ä¢	Missing approvals
‚Ä¢	Expired Fire NOC
‚Ä¢	Missing committees
‚Ä¢	Missing statutory disclosures
‚Ä¢	Improper infra
‚Ä¢	Outdated accreditation data
‚Ä¢	Safety non-compliance
‚Ä¢	Placement issues
Outputs:
‚Ä¢	severity (low/medium/high)
‚Ä¢	reason
‚Ä¢	evidence page/snippet
‚Ä¢	recommendation
This looks extremely mature in a demo.
________________________________________
üîµ MODULE 12 ‚Äî Evidence Intelligence System (Simplified)
For each extracted field:
‚Ä¢	show PDF page screenshot
‚Ä¢	highlight snippet area (approximate)
‚Ä¢	show text snippet
‚Ä¢	show page number
Evidence makes the system trustworthy.
________________________________________
üîµ MODULE 13 ‚Äî Institution Profile Dashboard
The main reviewer UI includes:
‚Ä¢	Institution metadata
‚Ä¢	KPI tiles
‚Ä¢	Sufficiency score
‚Ä¢	Compliance flags
‚Ä¢	Trend graphs
‚Ä¢	Document cards
‚Ä¢	Evidence viewer
‚Ä¢	Edit option
‚Ä¢	Audit log
‚Ä¢	Download report button
Everything is on one screen for fast review.
________________________________________
üîµ MODULE 14 ‚Äî Manual Edit System (Simplified)
Reviewer can edit:
‚Ä¢	extracted values
‚Ä¢	date fields
‚Ä¢	numeric fields
‚Ä¢	textual metadata
Reviewer must provide a reason.
Audit log stores:
‚Ä¢	old value
‚Ä¢	new value
‚Ä¢	reason
‚Ä¢	timestamp
This mirrors real regulatory workflows.
________________________________________
üîµ MODULE 15 ‚Äî Chatbot / Reviewer Assistant (GPT-5 Nano)
A floating assistant that can:
‚Ä¢	explain KPIs
‚Ä¢	explain missing documents
‚Ä¢	explain sufficiency
‚Ä¢	explain compliance flags
‚Ä¢	summarize institution profile
‚Ä¢	answer reviewer questions
‚Ä¢	generate comments for reports
It uses context from the batch.
Very strong for judges.
________________________________________
üîµ MODULE 16 ‚Äî Search System
Reviewer can search:
‚Ä¢	documents
‚Ä¢	extracted fields
‚Ä¢	compliance flags
‚Ä¢	audit logs
Small but useful.
Not over-engineered.
________________________________________
üîµ MODULE 17 ‚Äî Batch Tools (Simplified)
‚Ä¢	list batches
‚Ä¢	rerun batch
‚Ä¢	view logs
‚Ä¢	delete batch
‚Ä¢	download raw documents
Minimal and practical.
________________________________________
üîµ MODULE 18 ‚Äî PDF Report Generator
The system auto-generates a government-style report:
‚Ä¢	institution summary
‚Ä¢	KPI performance
‚Ä¢	sufficiency score
‚Ä¢	compliance flags
‚Ä¢	trend graphs
‚Ä¢	document table
‚Ä¢	evidence snapshots
‚Ä¢	metadata
‚Ä¢	reviewer comments
Powered by HTML ‚Üí PDF rendering.
Essential for UGC/AICTE use.
________________________________________
üîµ MODULE 19 ‚Äî WhatsApp Support (Simplified)
Not ingestion-heavy.
Just an alternate way to trigger the same analysis:
‚Ä¢	Reviewer sends documents
‚Ä¢	System runs pipeline
‚Ä¢	Returns compact summary
This is optional but great for demo.
________________________________________
üîµ MODULE 20 ‚Äî Dev & Deployment Support
Simplified:
‚Ä¢	Docker compose
‚Ä¢	ENV templates
‚Ä¢	README
‚Ä¢	No heavy production pipelines
________________________________________
üîµ MODULE 21 ‚Äî Security & Reliability
‚Ä¢	mode-specific routing
‚Ä¢	strict schema validation
‚Ä¢	LLM fallback model
‚Ä¢	sanitized logs
‚Ä¢	retry mechanism
‚Ä¢	token-based API access
Makes system stable and judge-safe.
________________________________________
‚≠ê WHAT WE ARE NOT BUILDING (VERY IMPORTANT)
‚ùå No institution login
‚ùå No institution-facing portal
‚ùå No approval workflow
‚ùå No admin/user roles
‚ùå No unnecessary microservices
‚ùå No trend interpolation
‚ùå No complex bounding boxes
‚ùå No undo/rollback engine
‚ùå No full WhatsApp ingestion pipeline
This keeps the system focused, realistic, aligned with PS, and easily implementable.
________________________________________
‚≠ê FINAL SUMMARY ‚Äî ONE PARAGRAPH
Smart Approval AI is a UGC/AICTE reviewer-focused AI system that automatically reads institutional documents, extracts structured data using GPT-5, analyzes historical performance, computes KPIs, evaluates document sufficiency, detects compliance risks, provides evidence for every extracted field, and generates an official report ‚Äî all displayed in a clean dashboard with a GPT-powered reviewer assistant. The system uses Unstructured-IO for document parsing, GPT-5 Nano/Mini for classification & extraction, FastAPI for AI pipeline processing, MongoDB for storing structured outputs, and Next.js for an intuitive reviewer dashboard. No institution login or workflow is included ‚Äî this is purely an AI evaluation tool, exactly matching the problem statement expectations.
